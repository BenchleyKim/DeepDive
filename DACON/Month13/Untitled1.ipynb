{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.1  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "DEVICE = None\n",
    "\n",
    "if torch.cuda.is_available() :\n",
    "    DEVICE = torch.device('cuda')\n",
    "else : \n",
    "    DEVICE = torch.device('cpu')\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "42\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "from glob import glob\n",
    "data_path = './data/train/'\n",
    "file_list = glob(data_path+'*.npy')\n",
    "file_list.sort()\n",
    "\n",
    "\n",
    "traindataset = []\n",
    "for i in range(len(file_list)) :\n",
    "    file = np.load(file_list[i])\n",
    "    file = np.float32(file)\n",
    "    file = torch.from_numpy(file) \n",
    "    traindataset.append(file)\n",
    "testdataset = traindataset[440:]\n",
    "traindataset = traindataset[:440]\n",
    "print(len(traindataset))\n",
    "print(len(testdataset))\n",
    "print(traindataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-be0523a7c1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mASICDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\" 해빙 데이터 \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatalist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ASICDataset(Dataset) :\n",
    "    \"\"\" 해빙 데이터 \"\"\"\n",
    "    def __init__(self, filelist, root_dir, transform = None) :\n",
    "        self.datalist = filelist\n",
    "        self.root_dir = root_dir\n",
    "        self.trainsform = transform\n",
    "    def __len__(self) :\n",
    "        return len(self.datalist)\n",
    "    def __getitem__(self,idx) :\n",
    "        if torch.is_tensor(idx) :\n",
    "            idx = idx.tolist()\n",
    "        file = np.load(self.datalist[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=136192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=32, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=136192, bias=True)\n",
      "  )\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\tTrain Loss: 1139.073730\n",
      "Train Epoch: 1 [1000/60000 (11%)]\tTrain Loss: 653.792114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(136192,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,32)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,136192)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "model = AE().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "def train(model, traindataset, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, image in enumerate(traindataset):\n",
    "        image = image.view(-1,136192).to(DEVICE)\n",
    "        target = image.view(-1,136192).to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        encoded, decoded = model(image)\n",
    "        loss = criterion(decoded, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0 :\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "def evalutate(model, testdataset) :\n",
    "    model.eval()\n",
    "    test_loss = 0 \n",
    "    real_image = []\n",
    "    gen_image = []\n",
    "    with torch.no_grad():\n",
    "        for image, _ in testdataset :\n",
    "            image = image.view(-1,136192).to(DEVICE)\n",
    "            target = image.view(-1,136192).to(DEVICE)\n",
    "            encoded, decoded = model(image)\n",
    "\n",
    "            test_loss += criterion(decoded,image).item()\n",
    "            real_image.append(image.to(\"cpu\"))\n",
    "            gen_image.append(decoded.to(\"cpu\"))\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, real_image, gen_image\n",
    "\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train(model, traindataset, optimizer, log_interval = 200)\n",
    "    test_loss, real_image, gen_image = evalutate(model, testdataset)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}\".format(epoch, test_loss))\n",
    "    f, a = plt.subplots(2, 10, figsize = (10, 4))\n",
    "    for i in range(10):\n",
    "        img = np.reshape(real_image[0][i], (28, 28))\n",
    "        a[0][i].imshow(img, cmap = \"gray_r\")\n",
    "        a[0][i].set_xticks(())\n",
    "        a[0][i].set_yticks(())\n",
    "    \n",
    "    for i in range(10):\n",
    "        img = np.reshape(gen_image[0][i], (28, 28))\n",
    "        a[1][i].imshow(img, cmap = \"gray_r\")\n",
    "        a[1][i].set_xticks(())\n",
    "        a[1][i].set_yticks(())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
